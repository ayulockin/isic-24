{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(os.cpu_count())\n",
    "\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "from glob import glob\n",
    "import wandb\n",
    "\n",
    "wandb.require(\"core\")\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torcheval.metrics.functional import binary_auroc\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from colorama import Fore, Style\n",
    "\n",
    "b_ = Fore.BLUE\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.set_float32_matmul_precision(\"highest\")\n",
    "\n",
    "\n",
    "# Set the random seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_df = pd.read_csv(\"../data/stratified_4_fold_new.csv\")\n",
    "train_metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, file_hdf: str, transform=None):\n",
    "        assert \"isic_id\" in df.columns\n",
    "        assert \"target\" in df.columns\n",
    "\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "        self.isic_ids = df[\"isic_id\"].values\n",
    "        self.labels = df.target.tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        isic_id = self.isic_ids[idx]\n",
    "        image = np.array(Image.open(BytesIO(self.fp_hdf[isic_id][()])))\n",
    "        label = self.labels[idx] / 1.0\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_samples(self, class_label):\n",
    "        indices = [i for i, label in enumerate(self.labels) if label == class_label]\n",
    "        return indices\n",
    "\n",
    "\n",
    "transforms_valid = A.Compose(\n",
    "    [\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"resnet18\", freeze_backbone=False, bias_value=None):\n",
    "        super(SkinClassifier, self).__init__()\n",
    "\n",
    "        # Load the specified pre-trained model\n",
    "        if model_name == \"resnet18\":\n",
    "            self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.fc.in_features\n",
    "            self.backbone.fc = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        elif model_name == \"convnext_tiny\":\n",
    "            self.backbone = models.convnext_tiny(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.classifier[2].in_features\n",
    "            self.backbone.classifier[2] = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        elif model_name == \"efficientnet_v2_s\":\n",
    "            self.backbone = models.efficientnet_v2_s(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.classifier[1].in_features\n",
    "            self.backbone.classifier[1] = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        elif model_name == \"efficientnet_v2_m\":\n",
    "            self.backbone = models.efficientnet_v2_m(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.classifier[1].in_features\n",
    "            self.backbone.classifier[1] = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        elif model_name == \"mobilenet_v3_small\":\n",
    "            self.backbone = models.mobilenet_v3_small(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.classifier[3].in_features\n",
    "            self.backbone.classifier[3] = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} not supported\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.backbone.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.backbone.features[7].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def get_clf_head(self, in_features, out_features, bias_value=None):\n",
    "        head = nn.Linear(in_features, out_features)\n",
    "        if bias_value:\n",
    "            nn.init.constant_(head.bias, bias_value)\n",
    "        return head\n",
    "\n",
    "    def count_parameters(self):\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        non_trainable_params = sum(\n",
    "            p.numel() for p in self.parameters() if not p.requires_grad\n",
    "        )\n",
    "        return trainable_params, non_trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders_and_stats(fold):\n",
    "    valid_df = train_metadata_df.loc[train_metadata_df.fold == fold]\n",
    "\n",
    "    num_workers = 24  # based on profiling\n",
    "\n",
    "    file_hdf = \"/home/ubuntu/ayusht/skin/data/train-image.hdf5\"\n",
    "    valid_dataset = SkinDataset(valid_df, file_hdf, transform=transforms_valid)\n",
    "    dataset_sizes = {\"val\": len(valid_dataset)}\n",
    "    print(dataset_sizes)\n",
    "\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        persistent_workers=True,\n",
    "    )\n",
    "\n",
    "    return valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = glob(\"../models/*.bin\")\n",
    "\n",
    "def filter_files_by_run_id(files, run_id):\n",
    "    \"\"\"\n",
    "    Filters the list of files by the given run ID.\n",
    "\n",
    "    Args:\n",
    "    files (list of str): List of file paths.\n",
    "    run_id (str): The run ID to filter by.\n",
    "\n",
    "    Returns:\n",
    "    list of str: List of file paths that contain the specified run ID.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(rf\"_{run_id}_\")\n",
    "    filtered_files = [file for file in files if pattern.search(file)]\n",
    "    return filtered_files\n",
    "\n",
    "\n",
    "def extract_valid_loss(file_name):\n",
    "    \"\"\"\n",
    "    Extracts the valid_loss value from the given file name.\n",
    "\n",
    "    Args:\n",
    "    file_name (str): The file name from which to extract the valid_loss.\n",
    "\n",
    "    Returns:\n",
    "    float: The extracted valid_loss value.\n",
    "    \"\"\"\n",
    "    match = re.search(r'valid_loss([\\d\\.]+)', file_name)\n",
    "    if match:\n",
    "        return float(match.group(1))\n",
    "    return float('inf')  # Return a very high value if valid_loss is not found\n",
    "\n",
    "def sort_files_by_valid_loss(files):\n",
    "    \"\"\"\n",
    "    Sorts the list of files by the valid_loss value in the file names.\n",
    "\n",
    "    Args:\n",
    "    files (list of str): List of file paths to sort.\n",
    "\n",
    "    Returns:\n",
    "    list of str: Sorted list of file paths by valid_loss.\n",
    "    \"\"\"\n",
    "    return sorted(files, key=extract_valid_loss)\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def infer_model(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    gts = []\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).flatten()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs).flatten()\n",
    "            preds.extend(torch.sigmoid(outputs))\n",
    "            gts.extend(labels)\n",
    "\n",
    "    preds = [pred.item() for pred in preds]\n",
    "    gts = [gt.item() for gt in gts]\n",
    "\n",
    "    return preds, gts\n",
    "\n",
    "\n",
    "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(solution.values)-1)\n",
    "    v_pred = np.array([1.0 - x for x in submission.values])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_positive_dist(preds):\n",
    "    positive_preds = np.array(preds)[np.array(gts) == 1.0]\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(positive_preds, bins=100)\n",
    "    plt.title('Prediction Distribution for Positive Class')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "def log_negative_dist(preds):\n",
    "    negative_preds = np.array(preds)[np.array(gts) == 0.0]\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(negative_preds, bins=100)\n",
    "    plt.title('Prediction Distribution for Negative Class')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ids = [\n",
    "    \"d9e6sc58\", # fold 0\n",
    "    \"7gpz5owu\", # fold 1\n",
    "    \"ylb6uvtj\", # fold 2\n",
    "    \"aa7biks12\", # fold 3\n",
    "]\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for fold, run_id in enumerate(run_ids):\n",
    "    if run_id not in scores.keys():\n",
    "        scores[run_id] = {}\n",
    "    # dataloader\n",
    "    valid_dataloader = get_dataloaders_and_stats(fold)\n",
    "\n",
    "    # models\n",
    "    runid_model_files = filter_files_by_run_id(model_files, run_id)\n",
    "    selected_model_files = sort_files_by_valid_loss(runid_model_files)[:3]\n",
    "    \n",
    "    for path in selected_model_files:\n",
    "        scores[run_id][path] = {}\n",
    "\n",
    "        # run = wandb.init(\n",
    "        #     project=\"isic_lesions_24\",\n",
    "        #     job_type=\"evaluate_folds\",\n",
    "        #     name=f'{run_id}_fold_{fold}_{path.split(\"/\")[-1]}_eval'\n",
    "        # )\n",
    "\n",
    "        model = SkinClassifier(\n",
    "            model_name=\"efficientnet_v2_s\"\n",
    "        )\n",
    "        model = model.to(device)\n",
    "        model = torch.compile(model)\n",
    "        state_dict = torch.load(path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "\n",
    "        preds, gts = infer_model(model, valid_dataloader)\n",
    "        score = comp_score(\n",
    "            pd.DataFrame(gts, columns=[\"target\"]),\n",
    "            pd.DataFrame(preds, columns=[\"prediction\"]),\n",
    "            \"\"\n",
    "        )\n",
    "        auroc = roc_auc_score(gts, preds)\n",
    "\n",
    "        # pos_plt = log_positive_dist(preds)\n",
    "        # neg_plt = log_negative_dist(preds)\n",
    "\n",
    "        scores[run_id][path][\"pAUC\"] = score\n",
    "        scores[run_id][path][\"AUROC\"] = auroc\n",
    "\n",
    "        # wandb.log({\n",
    "        #     \"pAUC\": score,\n",
    "        #     \"AUROC\": auroc,\n",
    "        # })\n",
    "\n",
    "        # wandb.finish()\n",
    "\n",
    "        model.to(\"cpu\")\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "    del valid_dataloader\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"fold0\", \"fold1\", \"fold2\", \"fold3\", \"val_loss0\", \"val_loss1\", \"val_loss2\", \"val_loss3\", \"pAUC\", \"std_pAUC\", \"AUROC\", \"atd_AUROC\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "ensemble_scores = {}\n",
    "\n",
    "fold_0_scores = scores[\"d9e6sc58\"]\n",
    "fold_1_scores = scores[\"7gpz5owu\"]\n",
    "fold_2_scores = scores[\"ylb6uvtj\"]\n",
    "fold_3_scores = scores[\"aa7biks12\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(fold_0_scores, fold_1_scores, fold_2_scores, fold_3_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "\n",
    "# Create a list to store results\n",
    "results = []\n",
    "\n",
    "# Calculate the scores for every combination of models\n",
    "for model_0, model_1, model_2, model_3 in product(fold_0_scores.keys(), fold_1_scores.keys(), fold_2_scores.keys(), fold_3_scores.keys()):\n",
    "    combined_pAUC = np.mean([fold_0_scores[model_0]['pAUC'], fold_1_scores[model_1]['pAUC'], fold_2_scores[model_2]['pAUC'], fold_3_scores[model_3]['pAUC']])\n",
    "    combined_AUROC = np.mean([fold_0_scores[model_0]['AUROC'], fold_1_scores[model_1]['AUROC'], fold_2_scores[model_2]['AUROC'], fold_3_scores[model_3]['AUROC']])\n",
    "    \n",
    "    # Calculate std deviation\n",
    "    std_pAUC = np.std([fold_0_scores[model_0]['pAUC'], fold_1_scores[model_1]['pAUC'], fold_2_scores[model_2]['pAUC'], fold_3_scores[model_3]['pAUC']])\n",
    "    std_AUROC = np.std([fold_0_scores[model_0]['AUROC'], fold_1_scores[model_1]['AUROC'], fold_2_scores[model_2]['AUROC'], fold_3_scores[model_3]['AUROC']])\n",
    "    \n",
    "    # Extract val losses from model names\n",
    "    val_loss0 = float(model_0.split('_')[5][4:])\n",
    "    val_loss1 = float(model_1.split('_')[5][4:])\n",
    "    val_loss2 = float(model_2.split('_')[5][4:])\n",
    "    val_loss3 = float(model_3.split('_')[5][4:])\n",
    "    \n",
    "    results.append([model_0, model_1, model_2, model_3, val_loss0, val_loss1, val_loss2, val_loss3, combined_pAUC, std_pAUC, combined_AUROC, std_AUROC])\n",
    "\n",
    "# Create a DataFrame\n",
    "ensembles_df = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"fold0\", \"fold1\", \"fold2\", \"fold3\", \"val_loss0\", \"val_loss1\", \"val_loss2\", \"val_loss3\", \"pAUC\", \"std_pAUC\", \"AUROC\", \"std_AUROC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pAUC_row = ensembles_df.loc[ensembles_df['pAUC'].idxmax()]\n",
    "min_std_pAUC_row = ensembles_df.loc[ensembles_df['std_pAUC'].idxmin()]\n",
    "\n",
    "max_pAUC_row, min_std_pAUC_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df.sort_values(by='pAUC', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df.sort_values(by='std_pAUC', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of pAUC vs std_pAUC\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot\n",
    "plt.scatter(ensembles_df['pAUC'], ensembles_df['std_pAUC'], c='blue', alpha=0.5)\n",
    "plt.xlabel('pAUC')\n",
    "plt.ylabel('std_pAUC')\n",
    "plt.title('Scatter plot of pAUC vs std_pAUC')\n",
    "\n",
    "# Optionally, add annotations to the points\n",
    "for i, row in ensembles_df.iterrows():\n",
    "    plt.annotate(i, (row['pAUC'], row['std_pAUC']))\n",
    "\n",
    "# Show grid\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df.loc[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of pAUC vs std_pAUC with color indicating mean score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sc = plt.scatter(ensembles_df['pAUC'], ensembles_df['std_pAUC'], c=ensembles_df['AUROC'], cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(sc, label='AUROC')\n",
    "plt.xlabel('pAUC')\n",
    "plt.ylabel('std_pAUC')\n",
    "plt.title('Trade-off between pAUC and std_pAUC with AUROC as color')\n",
    "\n",
    "# Optionally, add annotations to the points\n",
    "for i, row in ensembles_df.iterrows():\n",
    "    plt.annotate(i, (row['pAUC'], row['std_pAUC']))\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df.loc[22].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df.loc[70].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"isic_lesions_24\",\n",
    "    job_type=\"evaluate_folds\",\n",
    ")\n",
    "\n",
    "wandb.log({\"ensembles_4_fold_combinations\": ensembles_df})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df.loc[\n",
    "    (ensembles_df.val_loss0 == ensembles_df.val_loss0.min()) & \n",
    "    (ensembles_df.val_loss1 == ensembles_df.val_loss1.min()) &\n",
    "    (ensembles_df.val_loss2 == ensembles_df.val_loss2.min()) & \n",
    "    (ensembles_df.val_loss3 == ensembles_df.val_loss3.min())\n",
    "].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembles_df.loc[46].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
