{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.cpu_count())\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.set_float32_matmul_precision(\"highest\")\n",
    "\n",
    "\n",
    "# Set the random seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80):\n",
    "    v_gt = abs(np.asarray(solution.values)-1)\n",
    "    v_pred = np.array([1.0 - x for x in submission.values])\n",
    "    max_fpr = abs(1-min_tpr)\n",
    "    partial_auc_scaled = roc_auc_score(v_gt, v_pred, max_fpr=max_fpr)\n",
    "    # change scale from [0.5, 1.0] to [0.5 * max_fpr**2, max_fpr]\n",
    "    # https://math.stackexchange.com/questions/914823/shift-numbers-into-a-different-range\n",
    "    partial_auc = 0.5 * max_fpr**2 + (max_fpr - 0.5 * max_fpr**2) / (1.0 - 0.5) * (partial_auc_scaled - 0.5)\n",
    "    return partial_auc\n",
    "\n",
    "\n",
    "def evaluate_and_plot(gts, preds):\n",
    "    print(comp_score(\n",
    "        pd.DataFrame(gts, columns=[\"target\"]),\n",
    "        pd.DataFrame(preds, columns=[\"prediction\"]),\n",
    "        \"\"\n",
    "    ))\n",
    "\n",
    "    auroc = roc_auc_score(gts, preds)\n",
    "    print(f\"AUROC: {auroc:.2f}\")\n",
    "\n",
    "    positive_preds = np.array(preds)[np.array(gts) == 1.0]\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(positive_preds, bins=100, kde=True)\n",
    "    plt.title('Prediction Distribution for Positive Class')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    negative_preds = np.array(preds)[np.array(gts) == 0.0]\n",
    "\n",
    "    # Plot the distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(negative_preds, bins=100, kde=True)\n",
    "    plt.title('Prediction Distribution for Negative Class')\n",
    "    plt.xlabel('Predicted Probability')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    # Compute the calibration curve\n",
    "    prob_true, prob_pred = calibration_curve(gts, preds, n_bins=100)\n",
    "\n",
    "    # Plot the calibration curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label='Calibration curve')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
    "    plt.title('Calibration Plot')\n",
    "    plt.xlabel('Mean Predicted Probability')\n",
    "    plt.ylabel('Fraction of Positives')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_df = pd.read_csv(\"/home/ubuntu/ayusht/skin/data/train-metadata.csv\")\n",
    "_train_metadata_df = pd.read_csv(\"../data/stratified_5_fold_train_metadata.csv\")\n",
    "train_metadata_df[\"fold\"] = _train_metadata_df[\"fold\"]\n",
    "print(f\"Train: {len(train_metadata_df)}\")\n",
    "\n",
    "train_df_1 = train_metadata_df.loc[train_metadata_df.fold == 0]\n",
    "train_df_2 = train_metadata_df.loc[train_metadata_df.fold == 2]\n",
    "train_df_3 = train_metadata_df.loc[train_metadata_df.fold == 3]\n",
    "train_df_4 = train_metadata_df.loc[train_metadata_df.fold == 4]\n",
    "train_df = pd.concat([train_df_1, train_df_2, train_df_3, train_df_4])\n",
    "\n",
    "valid_df = train_metadata_df.loc[train_metadata_df.fold == 1]\n",
    "print(f\"Train size: {len(train_df)} | Valid size: {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, file_hdf: str, transform=None):\n",
    "        assert \"isic_id\" in df.columns\n",
    "        assert \"target\" in df.columns\n",
    "\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "        self.isic_ids = df['isic_id'].values\n",
    "        self.labels = df.target.tolist()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        isic_id = self.isic_ids[idx]\n",
    "        image = np.array(Image.open(BytesIO(self.fp_hdf[isic_id][()])))\n",
    "        label = self.labels[idx] / 1.0\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label\n",
    "\n",
    "    def get_class_samples(self, class_label):\n",
    "        indices = [i for i, label in enumerate(self.labels) if label == class_label]\n",
    "        return indices\n",
    "\n",
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(124, 124),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_workers = 24  # based on profiling\n",
    "\n",
    "train_dataset = SkinDataset(\n",
    "    train_df,\n",
    "    \"/home/ubuntu/ayusht/skin/data/train-image.hdf5\",\n",
    "    transform=transforms,\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "valid_dataset = SkinDataset(\n",
    "    valid_df,\n",
    "    \"/home/ubuntu/ayusht/skin/data/train-image.hdf5\",\n",
    "    transform=transforms,\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"resnet18\", freeze_backbone=False, bias_value=None):\n",
    "        super(SkinClassifier, self).__init__()\n",
    "\n",
    "        # Load the specified pre-trained model\n",
    "        if model_name == \"resnet18\":\n",
    "            self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.fc.in_features\n",
    "            self.backbone.fc = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        elif model_name == \"convnext_tiny\":\n",
    "            self.backbone = models.convnext_tiny(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.classifier[2].in_features\n",
    "            self.backbone.classifier[2] = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        elif model_name == \"efficientnet_v2_s\":\n",
    "            self.backbone = models.efficientnet_v2_s(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.classifier[1].in_features\n",
    "            self.backbone.classifier[1] = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        elif model_name == \"efficientnet_v2_m\":\n",
    "            self.backbone = models.efficientnet_v2_m(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.classifier[1].in_features\n",
    "            self.backbone.classifier[1] = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        elif model_name == \"mobilenet_v3_small\":\n",
    "            self.backbone = models.mobilenet_v3_small(weights=\"IMAGENET1K_V1\")\n",
    "            if freeze_backbone:\n",
    "                self.freeze_backbone()\n",
    "            num_ftrs = self.backbone.classifier[3].in_features\n",
    "            self.backbone.classifier[3] = self.get_clf_head(num_ftrs, 1, bias_value)\n",
    "        else:\n",
    "            raise ValueError(f\"Model {model_name} not supported\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def freeze_backbone(self):\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # unfreeze last conv block\n",
    "        for param in self.backbone.features[6].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for param in self.backbone.features[7].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def get_clf_head(self, in_features, out_features, bias_value=None):\n",
    "        head = nn.Linear(in_features, out_features)\n",
    "        if bias_value:\n",
    "            nn.init.constant_(head.bias, bias_value)\n",
    "        return head\n",
    "\n",
    "    def count_parameters(self):\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        non_trainable_params = sum(\n",
    "            p.numel() for p in self.parameters() if not p.requires_grad\n",
    "        )\n",
    "        return trainable_params, non_trainable_params\n",
    "\n",
    "\n",
    "PATH = \"/home/ubuntu/ayusht/skin/models/efficientnet_v2_s_et8zbzbg_valid_loss1.4331852197647095_epoch30.bin\"\n",
    "\n",
    "model = SkinClassifier(\n",
    "    model_name=\"efficientnet_v2_s\", freeze_backbone=True,\n",
    ")\n",
    "model = model.to(device)\n",
    "model = torch.compile(model)\n",
    "state_dict = torch.load(PATH, map_location=device)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def infer_model(model, dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    preds = []\n",
    "    gts = []\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).flatten()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs).flatten()\n",
    "            preds.extend(torch.sigmoid(outputs))\n",
    "            gts.extend(labels)\n",
    "\n",
    "    preds = [pred.item() for pred in preds]\n",
    "    gts = [gt.item() for gt in gts]\n",
    "\n",
    "    return preds, gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds, train_gts = infer_model(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds, valid_gts = infer_model(model, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_preds) == len(train_dataset)\n",
    "assert len(valid_preds) == len(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot(train_gts, train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_and_plot(valid_gts, valid_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "def feature_engineering(df):\n",
    "    # New features to try...\n",
    "    df[\"lesion_size_ratio\"] = df[\"tbp_lv_minorAxisMM\"] / df[\"clin_size_long_diam_mm\"]\n",
    "    df[\"lesion_shape_index\"] = df[\"tbp_lv_areaMM2\"] / (df[\"tbp_lv_perimeterMM\"] ** 2)\n",
    "    df[\"hue_contrast\"] = (df[\"tbp_lv_H\"] - df[\"tbp_lv_Hext\"]).abs()\n",
    "    df[\"luminance_contrast\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs()\n",
    "    df[\"lesion_color_difference\"] = np.sqrt(df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2)\n",
    "    df[\"border_complexity\"] = df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"color_uniformity\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_radial_color_std_max\"]\n",
    "    df[\"3d_position_distance\"] = np.sqrt(df[\"tbp_lv_x\"] ** 2 + df[\"tbp_lv_y\"] ** 2 + df[\"tbp_lv_z\"] ** 2) \n",
    "    df[\"perimeter_to_area_ratio\"] = df[\"tbp_lv_perimeterMM\"] / df[\"tbp_lv_areaMM2\"]\n",
    "    df[\"area_to_perimeter_ratio\"] = df[\"tbp_lv_areaMM2\"] / df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"lesion_visibility_score\"] = df[\"tbp_lv_deltaLBnorm\"] + df[\"tbp_lv_norm_color\"]\n",
    "    df[\"combined_anatomical_site\"] = df[\"anatom_site_general\"] + \"_\" + df[\"tbp_lv_location\"]\n",
    "    df[\"symmetry_border_consistency\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"]\n",
    "    df[\"symmetry_border_consistency2\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_norm_border\"] / (df[\"tbp_lv_symm_2axis\"] + df[\"tbp_lv_norm_border\"])\n",
    "    df[\"color_consistency\"] = df[\"tbp_lv_stdL\"] / df[\"tbp_lv_Lext\"]\n",
    "    df[\"color_consistency2\"] = df[\"tbp_lv_stdL\"] * df[\"tbp_lv_Lext\"] / (df[\"tbp_lv_stdL\"] + df[\"tbp_lv_Lext\"])\n",
    "    \n",
    "    df[\"size_age_interaction\"] = df[\"clin_size_long_diam_mm\"] * df[\"age_approx\"]\n",
    "    df[\"hue_color_std_interaction\"] = df[\"tbp_lv_H\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"lesion_severity_index\"] = (df[\"tbp_lv_norm_border\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_eccentricity\"]) / 3\n",
    "    df[\"shape_complexity_index\"] = df[\"border_complexity\"] + df[\"lesion_shape_index\"]\n",
    "    df[\"color_contrast_index\"] = df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"] + df[\"tbp_lv_deltaLBnorm\"]\n",
    "    df[\"log_lesion_area\"] = np.log(df[\"tbp_lv_areaMM2\"] + 1)\n",
    "    df[\"normalized_lesion_size\"] = df[\"clin_size_long_diam_mm\"] / df[\"age_approx\"]\n",
    "    df[\"mean_hue_difference\"] = (df[\"tbp_lv_H\"] + df[\"tbp_lv_Hext\"]) / 2\n",
    "    df[\"std_dev_contrast\"] = np.sqrt((df[\"tbp_lv_deltaA\"] ** 2 + df[\"tbp_lv_deltaB\"] ** 2 + df[\"tbp_lv_deltaL\"] ** 2) / 3)\n",
    "    df[\"color_shape_composite_index\"] = (df[\"tbp_lv_color_std_mean\"] + df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_symm_2axis\"]) / 3\n",
    "    df[\"3d_lesion_orientation\"] = np.arctan2(df[\"tbp_lv_y\"], df[\"tbp_lv_x\"])\n",
    "    df[\"overall_color_difference\"] = (df[\"tbp_lv_deltaA\"] + df[\"tbp_lv_deltaB\"] + df[\"tbp_lv_deltaL\"]) / 3\n",
    "    df[\"symmetry_perimeter_interaction\"] = df[\"tbp_lv_symm_2axis\"] * df[\"tbp_lv_perimeterMM\"]\n",
    "    df[\"comprehensive_lesion_index\"] = (df[\"tbp_lv_area_perim_ratio\"] + df[\"tbp_lv_eccentricity\"] + df[\"tbp_lv_norm_color\"] + df[\"tbp_lv_symm_2axis\"]) / 4\n",
    "\n",
    "    # Taken from: https://www.kaggle.com/code/dschettler8845/isic-detect-skin-cancer-let-s-learn-together\n",
    "    df[\"color_variance_ratio\"] = df[\"tbp_lv_color_std_mean\"] / df[\"tbp_lv_stdLExt\"]\n",
    "    df[\"border_color_interaction\"] = df[\"tbp_lv_norm_border\"] * df[\"tbp_lv_norm_color\"]\n",
    "    df[\"size_color_contrast_ratio\"] = df[\"clin_size_long_diam_mm\"] / df[\"tbp_lv_deltaLBnorm\"]\n",
    "    df[\"age_normalized_nevi_confidence\"] = df[\"tbp_lv_nevi_confidence\"] / df[\"age_approx\"]\n",
    "    df[\"color_asymmetry_index\"] = df[\"tbp_lv_radial_color_std_max\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"3d_volume_approximation\"] = df[\"tbp_lv_areaMM2\"] * np.sqrt(df[\"tbp_lv_x\"]**2 + df[\"tbp_lv_y\"]**2 + df[\"tbp_lv_z\"]**2)\n",
    "    df[\"color_range\"] = (df[\"tbp_lv_L\"] - df[\"tbp_lv_Lext\"]).abs() + (df[\"tbp_lv_A\"] - df[\"tbp_lv_Aext\"]).abs() + (df[\"tbp_lv_B\"] - df[\"tbp_lv_Bext\"]).abs()\n",
    "    df[\"shape_color_consistency\"] = df[\"tbp_lv_eccentricity\"] * df[\"tbp_lv_color_std_mean\"]\n",
    "    df[\"border_length_ratio\"] = df[\"tbp_lv_perimeterMM\"] / (2 * np.pi * np.sqrt(df[\"tbp_lv_areaMM2\"] / np.pi))\n",
    "    df[\"age_size_symmetry_index\"] = df[\"age_approx\"] * df[\"clin_size_long_diam_mm\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    df[\"age_size_symmetry_index2\"] = df[\"age_approx\"] * df[\"tbp_lv_areaMM2\"] * df[\"tbp_lv_symm_2axis\"]\n",
    "    # Until here.\n",
    "    \n",
    "    new_num_cols = [\n",
    "        \"lesion_size_ratio\", \"lesion_shape_index\", \"hue_contrast\",\n",
    "        \"luminance_contrast\", \"lesion_color_difference\", \"border_complexity\",\n",
    "        \"color_uniformity\", \"3d_position_distance\", \"perimeter_to_area_ratio\",\"area_to_perimeter_ratio\",\n",
    "        \"lesion_visibility_score\", \"symmetry_border_consistency\", \"symmetry_border_consistency2\", \"color_consistency\",\"color_consistency2\",\n",
    "\n",
    "        \"size_age_interaction\", \"hue_color_std_interaction\", \"lesion_severity_index\", \n",
    "        \"shape_complexity_index\", \"color_contrast_index\", \"log_lesion_area\",\n",
    "        \"normalized_lesion_size\", \"mean_hue_difference\", \"std_dev_contrast\",\n",
    "        \"color_shape_composite_index\", \"3d_lesion_orientation\", \"overall_color_difference\",\n",
    "        \"symmetry_perimeter_interaction\", \"comprehensive_lesion_index\",\n",
    "        \n",
    "        \"color_variance_ratio\", \"border_color_interaction\", \"size_color_contrast_ratio\",\n",
    "        \"age_normalized_nevi_confidence\", \"color_asymmetry_index\", \"3d_volume_approximation\",\n",
    "        \"color_range\", \"shape_color_consistency\", \"border_length_ratio\", \"age_size_symmetry_index\",\"age_size_symmetry_index2\",\n",
    "    ]\n",
    "    new_cat_cols = [\"combined_anatomical_site\"]\n",
    "    return df, new_num_cols, new_cat_cols\n",
    "\n",
    "num_cols = [\n",
    "    'age_approx', 'clin_size_long_diam_mm', 'tbp_lv_A', 'tbp_lv_Aext', 'tbp_lv_B', 'tbp_lv_Bext', \n",
    "    'tbp_lv_C', 'tbp_lv_Cext', 'tbp_lv_H', 'tbp_lv_Hext', 'tbp_lv_L', \n",
    "    'tbp_lv_Lext', 'tbp_lv_areaMM2', 'tbp_lv_area_perim_ratio', 'tbp_lv_color_std_mean', \n",
    "    'tbp_lv_deltaA', 'tbp_lv_deltaB', 'tbp_lv_deltaL', 'tbp_lv_deltaLB',\n",
    "    'tbp_lv_deltaLBnorm', 'tbp_lv_eccentricity', 'tbp_lv_minorAxisMM',\n",
    "    'tbp_lv_nevi_confidence', 'tbp_lv_norm_border', 'tbp_lv_norm_color',\n",
    "    'tbp_lv_perimeterMM', 'tbp_lv_radial_color_std_max', 'tbp_lv_stdL',\n",
    "    'tbp_lv_stdLExt', 'tbp_lv_symm_2axis', 'tbp_lv_symm_2axis_angle',\n",
    "    'tbp_lv_x', 'tbp_lv_y', 'tbp_lv_z',\n",
    "]\n",
    "\n",
    "train_df[num_cols] = train_df[num_cols].fillna(train_df[num_cols].median())\n",
    "valid_df[num_cols] = valid_df[num_cols].fillna(valid_df[num_cols].median())\n",
    "\n",
    "train_df, new_num_cols, new_cat_cols = feature_engineering(train_df.copy())\n",
    "valid_df, new_num_cols, new_cat_cols = feature_engineering(valid_df.copy())\n",
    "\n",
    "num_cols += new_num_cols\n",
    "\n",
    "# anatom_site_general\n",
    "cat_cols = [\"sex\", \"tbp_tile_type\", \"tbp_lv_location\", \"tbp_lv_location_simple\"] + new_cat_cols\n",
    "train_cols = num_cols + cat_cols\n",
    "\n",
    "category_encoder = OrdinalEncoder(\n",
    "    categories='auto',\n",
    "    dtype=int,\n",
    "    handle_unknown='use_encoded_value',\n",
    "    unknown_value=-2,\n",
    "    encoded_missing_value=-1,\n",
    ")\n",
    "\n",
    "X_cat = category_encoder.fit_transform(train_df[cat_cols])\n",
    "for c, cat_col in enumerate(cat_cols):\n",
    "    train_df[cat_col] = X_cat[:, c]\n",
    "\n",
    "X_cat = category_encoder.fit_transform(valid_df[cat_cols])\n",
    "for c, cat_col in enumerate(cat_cols):\n",
    "    valid_df[cat_col] = X_cat[:, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"n_estimators\": 200,\n",
    "    'learning_rate': 0.05,    \n",
    "    'lambda_l1': 0.0004681884533249742, \n",
    "    'lambda_l2': 8.765240856362274, \n",
    "    'num_leaves': 136, \n",
    "    'feature_fraction': 0.5392005444882538, \n",
    "    'bagging_fraction': 0.9577412548866563, \n",
    "    'bagging_freq': 6,\n",
    "    'min_child_samples': 60,\n",
    "    \"device\": \"gpu\"\n",
    "}\n",
    "\n",
    "oof_df = pd.DataFrame()\n",
    "_df_train = train_df.reset_index(drop=True)\n",
    "_df_valid = valid_df.reset_index(drop=True)\n",
    "# model = lgb.LGBMClassifier(**new_params)\n",
    "model = VotingClassifier([(f\"lgb_{i}\", lgb.LGBMClassifier(random_state=i, **new_params)) for i in range(7)], voting=\"soft\")\n",
    "model.fit(_df_train[train_cols], _df_train[\"target\"])\n",
    "lgb_preds = model.predict_proba(_df_valid[train_cols])[:, 1]\n",
    "score = comp_score(_df_valid[[\"target\"]], pd.DataFrame(lgb_preds, columns=[\"prediction\"]), \"\")\n",
    "print(f\"Partial AUC Score: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
